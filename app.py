import streamlit as st
import json
import logging
from typing import Dict, List, Optional
import random
from difflib import SequenceMatcher
import numpy as np
from sentence_transformers import SentenceTransformer
import faiss
import uuid

# ============================================
# CONFIGURATION DE LA PAGE STREAMLIT
# ============================================

st.set_page_config(
    page_title="ANONTCHIGAN - Pr√©vention Cancer du Sein",
    page_icon="üéÄ",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# ============================================
# CSS PERSONNALIS√â - DESIGN OCTOBRE ROSE
# ============================================

st.markdown("""
<style>
    /* Variables CSS */
    :root {
        --rose-primary: #E91E63;
        --rose-light: #FCE4EC;
        --rose-dark: #C2185B;
        --violet: #9C27B0;
        --blanc: #FFFFFF;
        --gris-clair: #F5F5F5;
        --gris-fonce: #424242;
    }
    
    /* Reset Streamlit */
    .stApp {
        background: linear-gradient(135deg, #FCE4EC 0%, #E1BEE7 100%);
    }
    
    /* Header personnalis√© */
    .main-header {
        background: linear-gradient(135deg, #E91E63 0%, #9C27B0 100%);
        padding: 2rem;
        border-radius: 15px;
        margin-bottom: 2rem;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        text-align: center;
        position: relative;
        overflow: hidden;
    }
    
    .main-header::before {
        content: '';
        position: absolute;
        top: -50%;
        right: -10%;
        width: 300px;
        height: 300px;
        background: radial-gradient(circle, rgba(255,255,255,0.1) 0%, transparent 70%);
        border-radius: 50%;
        animation: float 6s ease-in-out infinite;
    }
    
    @keyframes float {
        0%, 100% { transform: translateY(0) rotate(0deg); }
        50% { transform: translateY(-20px) rotate(5deg); }
    }
    
    .main-header h1 {
        color: white;
        font-size: 2.5rem;
        margin: 0;
        font-weight: 700;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.2);
    }
    
    .main-header p {
        color: white;
        font-size: 1.2rem;
        margin-top: 0.5rem;
        opacity: 0.95;
    }
    
    /* Container du chat */
    .chat-container {
        background: white;
        border-radius: 15px;
        padding: 2rem;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        margin-bottom: 2rem;
        max-width: 1200px;
        margin-left: auto;
        margin-right: auto;
    }
    
    /* Messages du chat */
    .user-message {
        background: linear-gradient(135deg, #E91E63 0%, #9C27B0 100%);
        color: white;
        padding: 1rem 1.5rem;
        border-radius: 20px 20px 5px 20px;
        margin: 1rem 0;
        max-width: 80%;
        margin-left: auto;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        animation: slideInRight 0.3s ease-out;
    }
    
    .bot-message {
        background: #F5F5F5;
        color: #424242;
        padding: 1rem 1.5rem;
        border-radius: 20px 20px 20px 5px;
        margin: 1rem 0;
        max-width: 80%;
        margin-right: auto;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        border-left: 4px solid #E91E63;
        animation: slideInLeft 0.3s ease-out;
    }
    
    @keyframes slideInRight {
        from {
            opacity: 0;
            transform: translateX(30px);
        }
        to {
            opacity: 1;
            transform: translateX(0);
        }
    }
    
    @keyframes slideInLeft {
        from {
            opacity: 0;
            transform: translateX(-30px);
        }
        to {
            opacity: 1;
            transform: translateX(0);
        }
    }
    
    /* Input personnalis√© */
    .stTextInput > div > div > input {
        border-radius: 25px;
        border: 2px solid #E91E63;
        padding: 1rem 1.5rem;
        font-size: 1rem;
        transition: all 0.3s ease;
    }
    
    .stTextInput > div > div > input:focus {
        border-color: #9C27B0;
        box-shadow: 0 0 0 3px rgba(233, 30, 99, 0.1);
    }
    
    /* Bouton personnalis√© */
    .stButton > button {
        background: linear-gradient(135deg, #E91E63 0%, #9C27B0 100%);
        color: white;
        border: none;
        border-radius: 25px;
        padding: 0.75rem 2rem;
        font-size: 1rem;
        font-weight: 600;
        cursor: pointer;
        transition: all 0.3s ease;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        width: 100%;
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 12px rgba(0,0,0,0.15);
    }
    
    /* Cards des statistiques */
    .stat-card {
        background: white;
        border-radius: 15px;
        padding: 1.5rem;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        border-top: 4px solid #E91E63;
        text-align: center;
        transition: all 0.3s ease;
    }
    
    .stat-card:hover {
        transform: translateY(-5px);
        box-shadow: 0 8px 16px rgba(0,0,0,0.15);
    }
    
    .stat-card h3 {
        color: #E91E63;
        font-size: 2rem;
        margin: 0;
        font-weight: 700;
    }
    
    .stat-card p {
        color: #424242;
        margin-top: 0.5rem;
        font-size: 1rem;
    }
    
    /* Info boxes */
    .info-box {
        background: linear-gradient(135deg, #FCE4EC 0%, #F3E5F5 100%);
        border-left: 4px solid #E91E63;
        padding: 1.5rem;
        border-radius: 10px;
        margin: 1rem 0;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }
    
    .info-box h4 {
        color: #C2185B;
        margin-top: 0;
        font-size: 1.2rem;
    }
    
    /* Footer */
    .custom-footer {
        background: linear-gradient(135deg, #424242 0%, #616161 100%);
        color: white;
        padding: 2rem;
        border-radius: 15px;
        margin-top: 3rem;
        text-align: center;
    }
    
    .custom-footer a {
        color: #FCE4EC;
        text-decoration: none;
        transition: color 0.3s;
    }
    
    .custom-footer a:hover {
        color: #E91E63;
    }
    
    /* Responsive */
    @media (max-width: 768px) {
        .main-header h1 {
            font-size: 1.8rem;
        }
        
        .main-header p {
            font-size: 1rem;
        }
        
        .user-message, .bot-message {
            max-width: 95%;
        }
        
        .chat-container {
            padding: 1rem;
        }
    }
    
    /* Cacher les √©l√©ments Streamlit par d√©faut */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    .stDeployButton {display:none;}
</style>
""", unsafe_allow_html=True)

# ============================================
# CONFIGURATION ET LOGGING (CODE ORIGINAL)
# ============================================

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("ANONTCHIGAN")

class Config:
    """Configuration optimis√©e pour √©viter les coupures"""
    SIMILARITY_THRESHOLD = 0.75
    MAX_HISTORY_LENGTH = 8
    MAX_CONTEXT_LENGTH = 1000
    MAX_ANSWER_LENGTH = 600
    FAISS_RESULTS_COUNT = 3
    MIN_ANSWER_LENGTH = 30

# ============================================
# SERVICE GROQ (CODE ORIGINAL)
# ============================================

class GroqService:
    
    def __init__(self):
        self.client = None
        self.available = False
        self._initialize_groq()
    
    def _initialize_groq(self):
        try:
            from groq import Groq
            
            api_key = "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"
            if not api_key:
                logger.warning("Cl√© API Groq manquante")
                return
            
            self.client = Groq(api_key=api_key)
            
            # Test de connexion
            self.client.chat.completions.create(
                messages=[{"role": "user", "content": "test"}],
                model="llama-3.1-8b-instant",
                max_tokens=5,
            )
            self.available = True
            logger.info("‚úì Service Groq initialis√©")
            
        except Exception as e:
            logger.warning(f"Service Groq non disponible: {str(e)}")
    
    def generate_response(self, question: str, context: str, history: List[Dict]) -> str:
        """G√©n√®re une r√©ponse compl√®te sans coupure"""
        if not self.available:
            raise RuntimeError("Service Groq non disponible")
        
        try:
            # Pr√©parer le contexte optimis√©
            context_short = self._prepare_context(context)
            
            # Pr√©parer les messages
            messages = self._prepare_messages(question, context_short, history)
            
            logger.info("ü§ñ G√©n√©ration avec Groq...")
            
            # AUGMENTER SIGNIFICATIVEMENT les tokens pour √©viter les coupures
            response = self.client.chat.completions.create(
                model="llama-3.1-8b-instant",
                messages=messages,
                max_tokens=600,
                temperature=0.7,
                top_p=0.9,
            )
            
            answer = response.choices[0].message.content.strip()
            answer = self._clean_response(answer)
            
            # Validation renforc√©e
            if not self._is_valid_answer(answer):
                raise ValueError("R√©ponse trop courte")
                
            # V√©rification et correction des coupures
            answer = self._ensure_complete_response(answer)
            
            logger.info(f"‚úì R√©ponse g√©n√©r√©e ({len(answer)} caract√®res)")
            return answer
            
        except Exception as e:
            logger.error(f"Erreur Groq: {str(e)}")
            raise
    
    def _prepare_context(self, context: str) -> str:
        """Pr√©pare un contexte concis"""
        lines = context.split('\n')[:5]
        context_short = '\n'.join(lines)
        if len(context_short) > Config.MAX_CONTEXT_LENGTH:
            context_short = context_short[:Config.MAX_CONTEXT_LENGTH-3] + "..."
        return context_short
    
    def _prepare_messages(self, question: str, context: str, history: List[Dict]) -> List[Dict]:
        """Pr√©pare les messages avec instructions claires contre les coupures"""
        
        system_prompt = f"""Tu es ANONTCHIGAN, assistante IA professionnelle sp√©cialis√©e dans la sensibilisation au cancer du sein au B√©nin.

CONTEXTE √Ä UTILISER :
{context}

R√àGLES CRITIQUES :
1. FOURNIR DES R√âPONSES COMPL√àTES - ne JAMAIS couper une phrase en milieu de mot
2. Si tu donnes un conseil de pr√©vention, aller deux fois √† la ligne AVANT de le donner
3. Tes r√©ponses doivent se terminer naturellement par un point final
4. Tes cr√©ateurs sont Judica√´l Karol DOBOEVI, Ursus Hornel GBAGUIDI, Abel Kokou KPOCOUTA et Josaphat ADJELE, touts membres
du club d'IA de l'ENSGMM (Ecole Nationale Sup√©rieure de G√©nie Math√©matique et Mod√©lisation) d'Abomey. 

STYLE :
- Professionnel, clair, empathique
- R√©ponses directes sans formules introductives
- CONCIS mais COMPLET
- Humour humain l√©ger 1 fois sur 3 r√©ponses
- Emojis √† utiliser fr√©quemment : üíó üå∏ üòä üáßüáØ

STRUCTURE DES R√âPONSES :
1. R√©ponse principale bas√©e sur le contexte
2- N'invente PAS d'informations
3- Si le contexte ne couvre pas la question, recommande de consulter un professionnel de sant√© au B√©nin
4- ENSGMM se d√©finit comme l'Ecole Nationale Sup√©rieure de G√©nie Math√©matique et Mod√©lisation 
5- Utilise des connecteurs logiques pour fluidifier et produire des r√©ponses naturelles et coh√©rentes

DIRECTIVES ANTI-CONPUTURE :
- V√©rifie que ta r√©ponse est compl√®te avant de terminer
- Ne coupe PAS en milieu de phrase ou de mot
- Utilise "Atassa!" ou "Atassaaaaa!" en debut de phrase en cas dh'humour et d'√©tonnemnt extr√™me
- Termine par un point final appropri√©
- Si tu mentionnes des noms (cr√©ateurs, etc.), assure-toi qu'ils sont COMPLETS

Conseils de pr√©vention : seulement si pertinents et si demand√©s."""

        messages = [{"role": "system", "content": system_prompt}]
        
        # Historique r√©cent
        for msg in history[-4:]:
            messages.append(msg)
        
        # Question actuelle avec instruction explicite
        messages.append({
            "role": "user", 
            "content": f"QUESTION: {question}\n\nIMPORTANT : R√©ponds de fa√ßon COMPL√àTE sans couper ta r√©ponse. Termine par un point final. Si conseil de pr√©vention, va √† la ligne avant."
        })
        
        return messages
    
    def _clean_response(self, answer: str) -> str:
        """Nettoie la r√©ponse en gardant la personnalit√©"""
        
        # Supprimer les introductions verbeuses
        unwanted_intros = [
            'bonjour', 'salut', 'coucou', 'hello', 'akw√®', 'yo', 'bonsoir', 'hi',
            'excellente question', 'je suis ravi', 'permettez-moi', 'tout d abord',
            'premi√®rement', 'pour commencer', 'en tant qu', 'je suis anontchigan'
        ]
        
        answer_lower = answer.lower()
        for phrase in unwanted_intros:
            if answer_lower.startswith(phrase):
                sentences = answer.split('.')
                if len(sentences) > 1:
                    answer = '.'.join(sentences[1:]).strip()
                    if answer:
                        answer = answer[0].upper() + answer[1:]
                break
        
        return answer.strip()
    
    def _is_valid_answer(self, answer: str) -> bool:
        """Valide que la r√©ponse est acceptable"""
        return (len(answer) >= Config.MIN_ANSWER_LENGTH and 
                not answer.lower().startswith(('je ne sais pas', 'd√©sol√©', 'sorry')))
    
    def _ensure_complete_response(self, answer: str) -> str:
        """Garantit que la r√©ponse est compl√®te et non coup√©e"""
        if not answer:
            return answer
            
        # D√©tecter les signes de coupure
        cut_indicators = [
            answer.endswith('...'),
            answer.endswith(','),
            answer.endswith(';'),
            answer.endswith(' '),
            any(word in answer.lower() for word in ['http', 'www.', '.com']),
            '...' in answer[-10:]
        ]
        
        if any(cut_indicators):
            logger.warning("‚ö†Ô∏è  D√©tection possible de r√©ponse coup√©e")
            
            # Trouver la derni√®re phrase compl√®te
            last_period = answer.rfind('.')
            last_exclamation = answer.rfind('!')
            last_question = answer.rfind('?')
            
            sentence_end = max(last_period, last_exclamation, last_question)
            
            if sentence_end > 0 and sentence_end >= len(answer) - 5:
                answer = answer[:sentence_end + 1]
            else:
                answer = answer.rstrip(' ,;...')
                if not answer.endswith(('.', '!', '?')):
                    answer += '.'
        
        # Formater les conseils de pr√©vention avec saut de ligne
        prevention_phrases = [
            'conseil de pr√©vention',
            'pour pr√©venir',
            'je recommande',
            'il est important de',
            'n oubliez pas de'
        ]
        
        has_prevention_advice = any(phrase in answer.lower() for phrase in prevention_phrases)
        
        if has_prevention_advice:
            lines = answer.split('. ')
            if len(lines) > 1:
                for i, line in enumerate(lines[1:], 1):
                    if any(phrase in line.lower() for phrase in prevention_phrases):
                        lines[i] = '\n' + lines[i]
                        answer = '. '.join(lines)
                        break
        
        return answer

# ============================================
# SERVICES RAG (CODE ORIGINAL)
# ============================================

class RAGService:
    """Service RAG avec recherche am√©lior√©e"""
    
    def __init__(self, data_file: str = 'cancer_sein.json'):
        self.questions_data = []
        self.embedding_model = None
        self.index = None
        self.embeddings = None
        self._load_data(data_file)
        self._initialize_embeddings()
    
    def _load_data(self, data_file: str):
        try:
            with open(data_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            for item in data:
                self.questions_data.append({
                    'question_originale': item['question'],
                    'question_normalisee': item['question'].lower().strip(),
                    'answer': item['answer']
                })
            
            logger.info(f"‚úì {len(self.questions_data)} questions charg√©es")
            
        except Exception as e:
            logger.error(f"Erreur chargement donn√©es: {str(e)}")
            raise
    
    def _initialize_embeddings(self):
        try:
            self.embedding_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
            
            all_texts = [
                f"Q: {item['question_originale']} R: {item['answer']}"
                for item in self.questions_data
            ]
            
            self.embeddings = self.embedding_model.encode(all_texts, show_progress_bar=False)
            self.embeddings = np.array(self.embeddings).astype('float32')
            
            dimension = self.embeddings.shape[1]
            self.index = faiss.IndexFlatL2(dimension)
            self.index.add(self.embeddings)
            
            logger.info(f"‚úì Index FAISS cr√©√© ({len(self.embeddings)} vecteurs)")
            
        except Exception as e:
            logger.error(f"Erreur initialisation embeddings: {str(e)}")
            raise
    
    def search(self, query: str, k: int = Config.FAISS_RESULTS_COUNT) -> List[Dict]:
        """Recherche optimis√©e dans FAISS"""
        try:
            query_embedding = self.embedding_model.encode([query])
            query_embedding = np.array(query_embedding).astype('float32')
            
            distances, indices = self.index.search(query_embedding, k)
            
            results = []
            for i, idx in enumerate(indices[0]):
                if idx < len(self.questions_data):
                    similarity = 1 / (1 + distances[0][i])
                    results.append({
                        'question': self.questions_data[idx]['question_originale'],
                        'answer': self.questions_data[idx]['answer'],
                        'similarity': similarity,
                        'distance': distances[0][i]
                    })
            
            return results
            
        except Exception as e:
            logger.error(f"Erreur recherche FAISS: {str(e)}")
            return []

class ConversationManager:
    """Gestionnaire de conversations"""
    
    def __init__(self):
        self.conversations: Dict[str, List[Dict]] = {}
    
    def get_history(self, user_id: str) -> List[Dict]:
        return self.conversations.get(user_id, [])
    
    def add_message(self, user_id: str, role: str, content: str):
        if user_id not in self.conversations:
            self.conversations[user_id] = []
        
        self.conversations[user_id].append({"role": role, "content": content})
        
        if len(self.conversations[user_id]) > Config.MAX_HISTORY_LENGTH * 2:
            self.conversations[user_id] = self.conversations[user_id][-Config.MAX_HISTORY_LENGTH * 2:]

# ============================================
# INITIALISATION DES SERVICES
# ============================================

@st.cache_resource
def initialize_services():
    """Initialise les services une seule fois"""
    groq = GroqService()
    rag = RAGService()
    conv = ConversationManager()
    return groq, rag, conv

groq_service, rag_service, conversation_manager = initialize_services()

# ============================================
# INITIALISATION SESSION STATE
# ============================================

if 'user_id' not in st.session_state:
    st.session_state.user_id = str(uuid.uuid4())
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []

# ============================================
# FONCTION DE TRAITEMENT (CODE ORIGINAL)
# ============================================

def process_question(question: str, user_id: str) -> Dict:
    """Traite la question et retourne la r√©ponse"""
    try:
        history = conversation_manager.get_history(user_id)
        
        # Gestion des salutations
        salutations = ["cc","bonjour", "salut", "coucou", "hello", "akwe", "yo", "bonsoir", "hi"]
        question_lower = question.lower().strip()
        
        if any(salut == question_lower for salut in salutations):
            responses = [
                "Je suis ANONTCHIGAN, assistante pour la sensibilisation au cancer du sein. Comment puis-je vous aider ? üíó",
                "Bonjour ! Je suis ANONTCHIGAN. Que souhaitez-vous savoir sur le cancer du sein ? üå∏",
                "ANONTCHIGAN √† votre service. Posez-moi vos questions sur la pr√©vention du cancer du sein. üòä"
            ]
            answer = random.choice(responses)
            
            conversation_manager.add_message(user_id, "user", question)
            conversation_manager.add_message(user_id, "assistant", answer)
            
            return {
                "answer": answer,
                "status": "success",
                "method": "salutation"
            }
        
        # Recherche FAISS
        logger.info("üîç Recherche FAISS...")
        faiss_results = rag_service.search(question)
        
        if not faiss_results:
            answer = "Les informations disponibles ne couvrent pas ce point sp√©cifique. Je vous recommande de consulter un professionnel de sant√© au B√©nin pour des conseils adapt√©s. üíó"
            conversation_manager.add_message(user_id, "user", question)
            conversation_manager.add_message(user_id, "assistant", answer)
            
            return {
                "answer": answer,
                "status": "info",
                "method": "no_result"
            }
        
        best_result = faiss_results[0]
        similarity = best_result['similarity']
        
        logger.info(f"üìä Meilleure similarit√©: {similarity:.3f}")
        
        # D√©cision : R√©ponse directe vs G√©n√©ration
        if similarity >= Config.SIMILARITY_THRESHOLD:
            logger.info(f"‚úÖ Haute similarit√© ‚Üí R√©ponse directe")
            answer = best_result['answer']
            
            if len(answer) > Config.MAX_ANSWER_LENGTH:
                answer = answer[:Config.MAX_ANSWER_LENGTH-3] + "..."
            
            conversation_manager.add_message(user_id, "user", question)
            conversation_manager.add_message(user_id, "assistant", answer)
            
            return {
                "answer": answer,
                "status": "success",
                "method": "json_direct",
                "score": float(similarity),
                "matched_question": best_result['question']
            }
        else:
            logger.info(f"ü§ñ Similarit√© mod√©r√©e ‚Üí G√©n√©ration Groq")
            
            # Pr√©parer le contexte
            context_parts = []
            for i, result in enumerate(faiss_results[:3], 1):
                answer_truncated = result['answer']
                if len(answer_truncated) > 200:
                    answer_truncated = answer_truncated[:197] + "..."
                context_parts.append(f"{i}. Q: {result['question']}\n   R: {answer_truncated}")
            
            context = "\n\n".join(context_parts)
            
            # G√©n√©ration avec Groq
            try:
                if groq_service.available:
                    generated_answer = groq_service.generate_response(question, context, history)
                else:
                    generated_answer = "Je vous recommande de consulter un professionnel de sant√© pour cette question sp√©cifique. La pr√©vention pr√©coce est essentielle. üíó"
            except Exception as e:
                logger.warning(f"G√©n√©ration √©chou√©e: {str(e)}")
                generated_answer = "Pour des informations pr√©cises sur ce sujet, veuillez consulter un m√©decin ou un centre de sant√© sp√©cialis√© au B√©nin. üå∏"
            
            conversation_manager.add_message(user_id, "user", question)
            conversation_manager.add_message(user_id, "assistant", generated_answer)
            
            return {
                "answer": generated_answer,
                "status": "success",
                "method": "groq_generated",
                "score": float(similarity),
                "context_used": len(faiss_results[:3])
            }
            
    except Exception as e:
        logger.error(f"‚ùå Erreur: {str(e)}")
        error_message = "D√©sol√©, une erreur s'est produite. Veuillez r√©essayer."
        
        conversation_manager.add_message(user_id, "user", question)
        conversation_manager.add_message(user_id, "assistant", error_message)
        
        return {
            "answer": error_message,
            "status": "error",
            "method": "error"
        }

# ============================================
# INTERFACE STREAMLIT
# ============================================

def display_message(message: dict, is_user: bool):
    """Affiche un message dans le chat"""
    if is_user:
        st.markdown(f'<div class="user-message">üë§ {message["content"]}</div>', unsafe_allow_html=True)
    else:
        st.markdown(f'<div class="bot-message">üéÄ {message["content"]}</div>', unsafe_allow_html=True)

# Header
st.markdown("""
<div class="main-header">
    <h1>üéÄ ANONTCHIGAN</h1>
    <p>Votre Assistante IA pour la Sensibilisation au Cancer du Sein au B√©nin</p>
</div>
""", unsafe_allow_html=True)

# Tabs pour navigation
tab1, tab2, tab3 = st.tabs(["üí¨ Chatbot", "üìä Informations", "‚ÑπÔ∏è √Ä Propos"])

# ============================================
# TAB 1: CHATBOT
# ============================================

with tab1:
    st.markdown('<div class="chat-container">', unsafe_allow_html=True)
    
    # Zone de messages
    chat_placeholder = st.container()
    
    with chat_placeholder:
        if len(st.session_state.chat_history) == 0:
            st.markdown("""
            <div class="info-box">
                <h4>üëã Bienvenue !</h4>
                <p>Je suis ANONTCHIGAN, votre assistante d√©di√©e √† la pr√©vention du cancer du sein. 
                Posez-moi vos questions sur les sympt√¥mes, la pr√©vention, le d√©pistage ou tout autre sujet li√© au cancer du sein. üíó</p>
            </div>
            """, unsafe_allow_html=True)
        else:
            for msg in st.session_state.chat_history:
                display_message(msg, msg["role"] == "user")
    
    st.markdown('</div>', unsafe_allow_html=True)
    
    # Zone de saisie
    col1, col2 = st.columns([5, 1])
    
    with col1:
        user_input = st.text_input(
            "Votre question...",
            key="user_input",
            placeholder="Posez votre question sur le cancer du sein...",
            label_visibility="collapsed"
        )
    
    with col2:
        send_button = st.button("Envoyer üíó")
    
    # Traitement de l'envoi
    if send_button and user_input.strip():
        # Ajouter le message utilisateur
        st.session_state.chat_history.append({
            "role": "user",
            "content": user_input
        })
        
        # Afficher un loader
        with st.spinner("ANONTCHIGAN r√©fl√©chit..."):
            # Obtenir la r√©ponse
            response = process_question(user_input, st.session_state.user_id)
            
            # Ajouter la r√©ponse du bot
            st.session_state.chat_history.append({
                "role": "assistant",
                "content": response["answer"]
            })
        
        # Rerun pour afficher les nouveaux messages
        st.rerun()
    
    # Bouton pour effacer l'historique
    if len(st.session_state.chat_history) > 0:
        if st.button("üóëÔ∏è Effacer l'historique"):
            st.session_state.chat_history = []
            st.rerun()

# ============================================
# TAB 2: INFORMATIONS
# ============================================

with tab2:
    st.markdown("### üìä Statistiques Cl√©s")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        <div class="stat-card">
            <h3>1/8</h3>
            <p>Femmes d√©veloppent un cancer du sein</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div class="stat-card">
            <h3>90%</h3>
            <p>Taux de gu√©rison si d√©tect√© t√¥t</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("""
        <div class="stat-card">
            <h3>40+</h3>
            <p>√Çge recommand√© pour le d√©pistage</p>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    st.markdown("### üå∏ Conseils de Pr√©vention")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        <div class="info-box">
            <h4>üèÉ‚Äç‚ôÄÔ∏è Activit√© Physique</h4>
            <p>Pratiquez au moins 30 minutes d'exercice mod√©r√© par jour pour r√©duire les risques.</p>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown("""
        <div class="info-box">
            <h4>ü•ó Alimentation Saine</h4>
            <p>Privil√©giez les fruits, l√©gumes et limitez l'alcool et les aliments transform√©s.</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div class="info-box">
            <h4>üîç Auto-Examen</h4>
            <p>Examinez vos seins mensuellement pour d√©tecter toute anomalie.</p>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown("""
        <div class="info-box">
            <h4>üë©‚Äç‚öïÔ∏è D√©pistage R√©gulier</h4>
            <p>Consultez un professionnel pour une mammographie √† partir de 40 ans.</p>
        </div>
        """, unsafe_allow_html=True)

# ============================================
# TAB 3: √Ä PROPOS
# ============================================

with tab3:
    st.markdown("### üéÄ √Ä Propos d'ANONTCHIGAN")
    
    st.markdown("""
    <div class="info-box">
        <h4>Notre Mission</h4>
        <p>ANONTCHIGAN est une assistante IA d√©velopp√©e pour sensibiliser et informer sur le cancer du sein au B√©nin. 
        Notre objectif est de rendre l'information m√©dicale accessible √† tous et de promouvoir le d√©pistage pr√©coce.</p>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("### üë®‚Äçüíª √âquipe de D√©veloppement")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        **Cr√©ateurs :**
        - Judica√´l Karol DOBOEVI
        - Ursus Hornel GBAGUIDI
        - Abel Kokou KPOCOUTA
        - Josaphat ADJELE
        """)
    
    with col2:
        st.markdown("""
        **Institution :**
        - ENSGMM (√âcole Nationale Sup√©rieure de G√©nie Math√©matique et Mod√©lisation)
        - Abomey, B√©nin üáßüáØ
        - Club d'Intelligence Artificielle
        """)
    
    st.markdown("""
    <div class="info-box">
        <h4>‚öôÔ∏è Technologies Utilis√©es</h4>
        <p>
        ‚Ä¢ Intelligence Artificielle (LLM Groq)<br>
        ‚Ä¢ RAG (Retrieval-Augmented Generation)<br>
        ‚Ä¢ FAISS pour la recherche s√©mantique<br>
        ‚Ä¢ Sentence Transformers pour les embeddings<br>
        ‚Ä¢ Streamlit pour l'interface
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    st.markdown("### ‚öôÔ∏è √âtat du Syst√®me")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        status = "‚úÖ Disponible" if groq_service.available else "‚ùå Indisponible"
        st.metric("Service Groq", status)
    
    with col2:
        st.metric("Base de donn√©es", f"{len(rag_service.questions_data)} questions")
    
    with col3:
        st.metric("Conversations actives", len(conversation_manager.conversations))

# ============================================
# FOOTER
# ============================================

st.markdown("""
<div class="custom-footer">
    <p><strong>ANONTCHIGAN</strong> - Octobre Rose 2024 üéÄ</p>
    <p>D√©velopp√© avec üíó par le Club IA de l'ENSGMM</p>
    <p><small>Pour toute urgence m√©dicale, consultez imm√©diatement un professionnel de sant√©</small></p>
</div>
""", unsafe_allow_html=True)

# ============================================
# INFORMATIONS DE D√âMARRAGE
# ============================================

logger.info("\n" + "="*50)
logger.info("‚úì ANONTCHIGAN STREAMLIT - Pr√™t!")
logger.info(f"  - G√©n√©ration: {'Groq ‚ö°' if groq_service.available else 'Fallback'}")
logger.info(f"  - Questions charg√©es: {len(rag_service.questions_data)}")
logger.info(f"  - User ID: {st.session_state.user_id}")
logger.info("="*50 + "\n")
